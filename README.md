# AdaBoost_Research_Core
This code includes a fully-functional version of AdaBoost from scratch which only 
returns specific values such as the learning coefficients used to weight hypotheses and
the specific vectors known as mistake dichotomies.

AdaBoost is a popular machine learning algorithm that iteratively updates a small set of parameters
using an exponentially defined weight update. I wrote a project in undergraduate at the University of Illinois at Chicago
that studies a specific kind of cycling behavior from this algorithm. This code is what I used to show that various 
behaviors of the algorithm hold under specific conditions and for certain small datasets. An online version of my paper
can be found at https://arxiv.org/abs/2210.07808 and there is more to come with this ReadMe.
